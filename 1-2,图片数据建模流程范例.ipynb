{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f1f7111a",
   "metadata": {},
   "source": [
    "# 1-2,图片数据建模流程范例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d66df564",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "#mac系统上pytorch和matplotlib在jupyter中同时跑需要更改环境变量\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"] = \"TRUE\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bd73b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torchvison\n",
    "!pip install torchmetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ecd187d",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# 导入操作系统库，用于与操作系统进行交互\n",
    "\n",
    "# 导入PyTorch深度学习框架，用于构建和训练神经网络模型\n",
    "import torch\n",
    "\n",
    "# 导入 torchvision 库，提供了用于计算机视觉任务的数据集、模型和工具\n",
    "import torchvision\n",
    "\n",
    "# 导入 torchkeras 库，提供了一些增强PyTorch的工具和扩展\n",
    "import torchkeras\n",
    "\n",
    "# 导入 torchmetrics 库，提供了用于评估模型性能的度量指标\n",
    "import torchmetrics\n",
    "\n",
    "print(\"torch.__version__ = \", torch.__version__)\n",
    "print(\"torchvision.__version__ = \", torchvision.__version__)\n",
    "print(\"torchkeras.__version__ = \", torchkeras.__version__)\n",
    "print(\"torchmetrics.__version__ = \", torchmetrics.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b1bde63",
   "metadata": {},
   "source": [
    "### 一，准备数据"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15a18555",
   "metadata": {},
   "source": [
    "cifar2数据集为cifar10数据集的子集，只包括前两种类别airplane和automobile。\n",
    "\n",
    "训练集有airplane和automobile图片各5000张，测试集有airplane和automobile图片各1000张。\n",
    "\n",
    "cifar2任务的目标是训练一个模型来对飞机airplane和机动车automobile两种图片进行分类。\n",
    "\n",
    "我们准备的Cifar2数据集的文件结构如下所示。\n",
    "\n",
    "![](./data/cifar2.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16ecef43",
   "metadata": {},
   "source": [
    "在Pytorch中构建图片数据管道通常有两种方法。\n",
    "\n",
    "第一种是使用torchvision中的datasets.ImageFolder来读取图片然后用DataLoader来并行加载。\n",
    "\n",
    "第二种是通过继承 torch.utils.data.Dataset 实现用户自定义读取逻辑然后用 DataLoader来并行加载。\n",
    "\n",
    "第二种方法是读取用户自定义数据集的通用方法，既可以读取图片数据集，也可以读取文本数据集。\n",
    "\n",
    "本篇我们介绍第一种方法。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61535b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 从PyTorch库中导入 nn 模块，它包含了神经网络的构建块，如层、激活函数等\n",
    "\n",
    "# 从 torch.utils.data 库中导入 DataLoader 类，用于批量加载数据\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# 从 torchvision 库中导入 transforms 模块并重命名为 T，它用于数据预处理和增强\n",
    "from torchvision import transforms as T\n",
    "\n",
    "# 从 torchvision 库中导入 datasets 模块，提供了一些常用的计算机视觉数据集\n",
    "from torchvision import datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a242a652",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义了一个名为 transform_img 的数据变换函数，用于将图像数据转换为 PyTorch 的张量（tensor）\n",
    "# T.ToTensor() 将图像数据从 PIL.Image 或 numpy.ndarray 格式转换为 PyTorch 张量\n",
    "transform_img = T.Compose([T.ToTensor()])\n",
    "\n",
    "\n",
    "# 定义了一个名为 transform_label 的函数，用于将标签数据转换为 PyTorch 的张量（tensor）\n",
    "# 这个函数接收一个参数 x，将其包装在一个张量中，并将其数据类型设置为 float\n",
    "def transform_label(x):\n",
    "    return torch.tensor([x]).float()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53f01ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建训练数据集 ds_train，使用 ImageFolder 数据集，该数据集假定数据按照类别存储在不同的子目录中\n",
    "# 参数 \"./eat_pytorch_datasets/cifar2/train/\" 指定训练数据集的根目录\n",
    "# transform 参数指定对图像数据的转换，使用了之前定义的 transform_img 函数，将图像转换为张量\n",
    "# target_transform 参数指定对标签数据的转换，使用了之前定义的 transform_label 函数，将标签转换为张量\n",
    "ds_train = datasets.ImageFolder(\"./eat_pytorch_datasets/cifar2/train/\",\n",
    "                                transform=transform_img, target_transform=transform_label)\n",
    "\n",
    "# 创建验证数据集 ds_val，使用 ImageFolder 数据集，该数据集假定数据按照类别存储在不同的子目录中\n",
    "# 参数 \"./eat_pytorch_datasets/cifar2/test/\" 指定验证数据集的根目录\n",
    "# transform 参数指定对图像数据的转换，使用了之前定义的 transform_img 函数，将图像转换为张量\n",
    "# target_transform 参数指定对标签数据的转换，使用了之前定义的 transform_label 函数，将标签转换为张量\n",
    "ds_val = datasets.ImageFolder(\"./eat_pytorch_datasets/cifar2/test/\",\n",
    "                              transform=transform_img, target_transform=transform_label)\n",
    "\n",
    "# 打印 ds_train 的类别映射，这将显示类别与索引的对应关系\n",
    "print(ds_train.class_to_idx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aec4c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建训练数据加载器 dl_train，使用 DataLoader 类\n",
    "# 参数 ds_train 是训练数据集，它将从中加载数据\n",
    "# batch_size 参数指定每个批次中包含的样本数量，这里设置为 50，表示每个批次加载 50 张图像\n",
    "# shuffle 参数设置为 True，表示在每个 epoch 开始时随机打乱数据顺序，有助于模型学习\n",
    "dl_train = DataLoader(ds_train, batch_size=50, shuffle=True)\n",
    "\n",
    "# 创建验证数据加载器 dl_val，使用 DataLoader 类\n",
    "# 参数 ds_val 是验证数据集，它将从中加载数据\n",
    "# batch_size 参数指定每个批次中包含的样本数量，这里设置为 50，表示每个批次加载 50 张图像\n",
    "# shuffle 参数设置为 False，表示不打乱验证数据的顺序，以确保验证结果的稳定性\n",
    "dl_val = DataLoader(ds_val, batch_size=50, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de412f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用 Jupyter Notebook 的魔术命令，将 matplotlib 图形嵌入到输出中\n",
    "%matplotlib inline\n",
    "\n",
    "# 配置图形的输出格式为 SVG\n",
    "%config InlineBackend.figure_format = 'svg'\n",
    "\n",
    "# 导入 matplotlib 的 pyplot 模块，用于绘制图形\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# 创建一个 8x8 英寸大小的图形窗口\n",
    "plt.figure(figsize=(8, 8))\n",
    "\n",
    "# 循环遍历并显示前 9 个训练样本\n",
    "for i in range(9):\n",
    "    # 从训练数据集中获取图像和标签\n",
    "    img, label = ds_train[i]\n",
    "\n",
    "    # 将图像张量的维度重新排列，从 (C, H, W) 转换为 (H, W, C)，以便 matplotlib 显示\n",
    "    img = img.permute(1, 2, 0)\n",
    "\n",
    "    # 创建一个子图，并设置标题为对应的标签\n",
    "    ax = plt.subplot(3, 3, i + 1)\n",
    "\n",
    "    '''\n",
    "    当解释以下代码行时：\n",
    "    这两行代码执行了以下操作：\n",
    "    1. `img = img.permute(1, 2, 0)`：\n",
    "        - `img` 是一个图像的张量，通常具有形状 `(C, H, W)`，其中 `C` 表示通道数（例如，彩色图像通常有3个通道：红色、绿色、蓝色），`H` 表示高度，`W` 表示宽度。\n",
    "        - `permute(1, 2, 0)` 是一个 PyTorch 张量的操作，它重新排列张量的维度。在这里，它将原始张量的维度从 `(C, H, W)` 重新排列为 `(H, W, C)`，这是因为 Matplotlib 需要图像的维度顺序为 `(H, W, C)` 才能正确显示图像。这个操作将通道维度移动到最后一个位置，以便图像在 Matplotlib 中正确渲染。\n",
    "    2. `ax = plt.subplot(3, 3, i + 1)`：\n",
    "        - 这行代码创建了一个子图（subplot），在 Matplotlib 中，子图是一个小的图形区域，可以在主图形窗口中容纳多个子图。\n",
    "        - 参数 `3, 3, i + 1` 指定了子图的网格布局。具体来说，`3, 3` 表示将主图形分成一个3x3的网格，`i + 1` 表示当前子图在这个网格中的位置，`i` 是循环变量，用于表示当前子图的索引。\n",
    "        - 这个操作在主图形窗口中创建了一个新的子图，并将其赋给变量 `ax`，以便后续对该子图进行设置，如设置标题、图像等。    \n",
    "    '''\n",
    "\n",
    "    ax.imshow(img.numpy())  # 显示图像\n",
    "    ax.set_title(\"label = %d\" % label.item())  # 设置子图标题\n",
    "    ax.set_xticks([])  # 隐藏 x 轴刻度\n",
    "    ax.set_yticks([])  # 隐藏 y 轴刻度\n",
    "\n",
    "# 显示图形窗口\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "443f6581",
   "metadata": {},
   "source": [
    "![](./data/1-2-查看样本.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "367ccf3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 遍历训练数据加载器 dl_train，以获取批次数据\n",
    "for features, labels in dl_train:\n",
    "    # 打印当前批次中图像数据的形状和标签数据的形状\n",
    "    # features 是图像数据的批次，labels 是对应的标签批次\n",
    "    print(\"图像数据形状:\", features.shape)\n",
    "    print(\"标签数据形状:\", labels.shape)\n",
    "    break  # 仅打印第一个批次以避免输出过多\n",
    "\n",
    "'''\n",
    "这部分代码用于检查训练数据加载器 `dl_train` 中的批次数据的形状。下面是对这部分代码的注释：\n",
    "在 PyTorch 中，默认的图像数据排列顺序是 Batch（批次大小）、Channel（通道数，如 RGB 通道为 3）、Width（宽度）、Height（高度）。\n",
    "`features.shape` 中的第一个维度表示批次大小，第二个维度表示通道数，第三和第四个维度表示图像的宽度和高度，打印的形状为 `[50, 3, 32, 32]` 表示一个批次包含 50 张图像，每张图像具有 3 个通道（RGB），宽度和高度分别为 32 像素。\n",
    "标签数据的形状中，第一个维度表示批次大小，第二个维度为 1，因为每个标签都是一个标量值，标签数据的形状为 `[50, 1]` 表示一个批次包含 50 个标签。\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c614279",
   "metadata": {},
   "source": [
    "### 二，定义模型"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d496cb9e",
   "metadata": {},
   "source": [
    "使用Pytorch通常有三种方式构建模型：使用nn.Sequential按层顺序构建模型，继承nn.Module基类构建自定义模型，继承nn.Module基类构建模型并辅助应用模型容器(nn.Sequential,nn.ModuleList,nn.ModuleDict)进行封装。\n",
    "\n",
    "此处选择通过继承nn.Module基类构建自定义模型。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dde64c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入 PyTorch 中的 nn 模块\n",
    "from torch import nn\n",
    "\n",
    "# 创建一个自适应最大池化层，指定输出大小为 (1, 1)\n",
    "pool = nn.AdaptiveMaxPool2d((1, 1))\n",
    "\n",
    "# 创建一个随机张量 t，大小为 (10, 8, 32, 32)\n",
    "t = torch.randn(10, 8, 32, 32)\n",
    "\n",
    "# 使用自适应最大池化层对张量 t 进行池化操作\n",
    "# 自适应最大池化会根据指定的输出大小自动计算池化核大小，并对输入进行池化\n",
    "# 这里的输出大小为 (1, 1)，表示在宽度和高度上都进行了自适应的最大池化\n",
    "output = pool(t)\n",
    "\n",
    "# 打印池化后的张量形状\n",
    "print(output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39d23d45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入 PyTorch 的 nn 模块\n",
    "from torch import nn\n",
    "\n",
    "\n",
    "# 定义一个名为 Net 的神经网络类，继承自 nn.Module\n",
    "class Net(nn.Module):\n",
    "\n",
    "    # 构造函数，在这里定义了神经网络的各个层\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "\n",
    "        # 第一个卷积层，输入通道数为 3，输出通道数为 32，卷积核大小为 3x3\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3)\n",
    "\n",
    "        # 最大池化层，池化核大小为 2x2，步幅为 2\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        # 第二个卷积层，输入通道数为 32，输出通道数为 64，卷积核大小为 5x5\n",
    "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=5)\n",
    "\n",
    "        # 二维 Dropout 层，用于随机丢弃部分神经元，防止过拟合\n",
    "        self.dropout = nn.Dropout2d(p=0.1)\n",
    "\n",
    "        # 自适应最大池化层，输出大小为 (1, 1)\n",
    "        self.adaptive_pool = nn.AdaptiveMaxPool2d((1, 1))\n",
    "\n",
    "        # 将输入张量展平为一维张量\n",
    "        self.flatten = nn.Flatten()\n",
    "\n",
    "        # 第一个全连接层，输入特征数为 64，输出特征数为 32\n",
    "        self.linear1 = nn.Linear(64, 32)\n",
    "\n",
    "        # ReLU 激活函数层\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "        # 第二个全连接层，输入特征数为 32，输出特征数为 1\n",
    "        self.linear2 = nn.Linear(32, 1)\n",
    "\n",
    "    # 前向传播函数，定义了数据在模型中的传递方式\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.pool(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.pool(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.adaptive_pool(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.linear1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.linear2(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "# 创建一个 Net 类的实例，即神经网络模型\n",
    "net = Net()\n",
    "\n",
    "# 打印神经网络的结构\n",
    "print(net)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "这个神经网络模型包含多个不同类型的层，每个层都有特定的作用和设置缘由。以下是每个层的解释和设置缘由：\n",
    "\n",
    "1. **卷积层 `self.conv1`**：\n",
    "   - 作用：卷积层用于从输入图像中提取特征，通过卷积操作可以检测图像中的边缘、纹理等局部特征。\n",
    "   - 设置缘由：这里的第一个卷积层具有3个输入通道（对应彩色图像的RGB通道）和32个输出通道，使用3x3的卷积核。这样的设置可以帮助模型学习图像的低级特征。\n",
    "\n",
    "2. **最大池化层 `self.pool`**：\n",
    "   - 作用：最大池化层用于减小特征图的大小，保留最显著的特征，同时降低计算复杂度。\n",
    "   - 设置缘由：池化核大小为2x2，步幅为2，这意味着特征图的大小将减小一半。这有助于减少模型参数，同时提取显著特征。\n",
    "\n",
    "3. **卷积层 `self.conv2`**：\n",
    "   - 作用：第二个卷积层进一步提取图像的高级特征，对先前卷积层的输出进行处理。\n",
    "   - 设置缘由：这里的第二个卷积层有32个输入通道（与前一层的输出通道数相同）和64个输出通道，使用5x5的卷积核。增加输出通道数和卷积核大小有助于捕获更复杂的特征。\n",
    "\n",
    "4. **二维 Dropout 层 `self.dropout`**：\n",
    "   - 作用：Dropout 层用于在训练过程中随机丢弃部分神经元，以减少过拟合。\n",
    "   - 设置缘由：设置丢弃率为0.1，表示在每个训练批次中，有10%的神经元被随机丢弃。这有助于提高模型的泛化能力。\n",
    "\n",
    "5. **自适应最大池化层 `self.adaptive_pool`**：\n",
    "   - 作用：自适应最大池化层将特征图的大小调整为固定大小，不受输入图像大小的影响。\n",
    "   - 设置缘由：输出大小设置为(1, 1)，这将确保无论输入图像的大小如何，都会得到固定大小的特征表示，用于后续全连接层的输入。\n",
    "\n",
    "6. **Flatten 层 `self.flatten`**：\n",
    "   - 作用：将多维特征张量展平为一维张量，以便连接到全连接层。\n",
    "   - 设置缘由：这一步是为了将自适应最大池化层的输出变成一维向量，以便输入到全连接层。\n",
    "\n",
    "7. **全连接层 `self.linear1` 和 `self.linear2`**：\n",
    "   - 作用：全连接层用于将卷积层和池化层提取的特征映射到最终的输出标签。\n",
    "   - 设置缘由：第一个全连接层有64个输入特征，32个输出特征；第二个全连接层有32个输入特征，1个输出特征（用于二分类问题）。这些全连接层将学习将高维特征映射到最终输出的关系。\n",
    "\n",
    "8. **ReLU 激活函数层 `self.relu`**：\n",
    "   - 作用：ReLU（Rectified Linear Unit）激活函数用于引入非线性性，帮助模型学习更复杂的特征表示。\n",
    "   - 设置缘由：在全连接层之间使用ReLU激活函数，有助于增强网络的表达能力。\n",
    "\n",
    "总体来说，这个神经网络模型是一个卷积神经网络（Convolutional Neural Network，CNN），用于处理图像分类任务。通过卷积层和池化层，它可以从图像中提取特征，然后通过全连接层将这些特征映射到最终的分类结果。Dropout 层和ReLU激活函数用于提高模型的泛化能力和非线性表示能力。自适应最大池化层确保了输入图像大小的不变性。不同层的设置经过调整，以在训练过程中有效地学习特定任务的特征表示。这个模型适用于二分类问题，其中最后一个全连接层输出一个标量用于分类。"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a35189c7007a1f68"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98f6d94d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入 torchkeras 库，用于模型摘要的打印\n",
    "import torchkeras\n",
    "\n",
    "# 使用 torchkeras 的 summary 函数打印模型摘要\n",
    "# 参数 net 是要打印摘要的神经网络模型\n",
    "# 参数 input_data 是输入数据的样本，用于确定输入形状\n",
    "torchkeras.summary(net, input_data=features)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a141ab6f",
   "metadata": {},
   "source": [
    "### 三，训练模型"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1dbb766",
   "metadata": {},
   "source": [
    "Pytorch通常需要用户编写自定义训练循环，训练循环的代码风格因人而异。\n",
    "\n",
    "有3类典型的训练循环代码风格：脚本形式训练循环，函数形式训练循环，类形式训练循环。\n",
    "\n",
    "此处介绍一种较通用的仿照Keras风格的函数形式的训练循环。\n",
    "\n",
    "该训练循环的代码也是torchkeras库的核心代码。\n",
    "\n",
    "torchkeras详情:  https://github.com/lyhue1991/torchkeras \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5beafb9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入所需的 Python 库和模块\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from torch import nn\n",
    "from copy import deepcopy\n",
    "\n",
    "\n",
    "# 定义一个打印日志的函数，用于输出训练过程中的信息\n",
    "def printlog(info):\n",
    "    nowtime = datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "    print(\"\\n\" + \"==========\" * 8 + \"%s\" % nowtime)\n",
    "    print(str(info) + \"\\n\")\n",
    "\n",
    "\n",
    "# 定义一个用于单步训练或验证的类\n",
    "class StepRunner:\n",
    "    # 构造函数\n",
    "    def __init__(self, net, loss_fn, stage=\"train\", metrics_dict=None, optimizer=None):\n",
    "        self.net, self.loss_fn, self.metrics_dict, self.stage = net, loss_fn, metrics_dict, stage\n",
    "        self.optimizer = optimizer\n",
    "\n",
    "    # 单步训练或验证的方法\n",
    "    def step(self, features, labels):\n",
    "        # 计算损失\n",
    "        preds = self.net(features)\n",
    "        loss = self.loss_fn(preds, labels)\n",
    "\n",
    "        # 反向传播与优化\n",
    "        if self.optimizer is not None and self.stage == \"train\":\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "            self.optimizer.zero_grad()\n",
    "\n",
    "        # 计算度量指标\n",
    "        step_metrics = {self.stage + \"_\" + name: metric_fn(preds, labels).item()\n",
    "                        for name, metric_fn in self.metrics_dict.items()}\n",
    "        return loss.item(), step_metrics\n",
    "\n",
    "    # 训练步骤\n",
    "    def train_step(self, features, labels):\n",
    "        self.net.train()  # 设置模型为训练模式，以便 dropout 层生效\n",
    "        return self.step(features, labels)\n",
    "\n",
    "    # 评估步骤\n",
    "    @torch.no_grad()\n",
    "    def eval_step(self, features, labels):\n",
    "        self.net.eval()  # 设置模型为评估模式，以便 dropout 层不生效\n",
    "        return self.step(features, labels)\n",
    "\n",
    "    def __call__(self, features, labels):\n",
    "        if self.stage == \"train\":\n",
    "            return self.train_step(features, labels)\n",
    "        else:\n",
    "            return self.eval_step(features, labels)\n",
    "\n",
    "\n",
    "# 定义一个用于整个 epoch 训练或验证的类\n",
    "class EpochRunner:\n",
    "    def __init__(self, steprunner):\n",
    "        self.steprunner = steprunner\n",
    "        self.stage = steprunner.stage\n",
    "\n",
    "    def __call__(self, dataloader):\n",
    "        total_loss, step = 0, 0\n",
    "        loop = tqdm(enumerate(dataloader), total=len(dataloader), file=sys.stdout)\n",
    "        for i, batch in loop:\n",
    "            loss, step_metrics = self.steprunner(*batch)\n",
    "            step_log = dict({self.stage + \"_loss\": loss}, **step_metrics)\n",
    "            total_loss += loss\n",
    "            step += 1\n",
    "            if i != len(dataloader) - 1:\n",
    "                loop.set_postfix(**step_log)\n",
    "            else:\n",
    "                epoch_loss = total_loss / step\n",
    "                epoch_metrics = {self.stage + \"_\" + name: metric_fn.compute().item()\n",
    "                                 for name, metric_fn in self.steprunner.metrics_dict.items()}\n",
    "                epoch_log = dict({self.stage + \"_loss\": epoch_loss}, **epoch_metrics)\n",
    "                loop.set_postfix(**epoch_log)\n",
    "\n",
    "                for name, metric_fn in self.steprunner.metrics_dict.items():\n",
    "                    metric_fn.reset()\n",
    "        return epoch_log\n",
    "\n",
    "\n",
    "# 定义一个函数来训练神经网络模型\n",
    "def train_model(net, optimizer, loss_fn, metrics_dict,\n",
    "                train_data, val_data=None,\n",
    "                epochs=10, ckpt_path='checkpoint.pt',\n",
    "                patience=5, monitor=\"val_loss\", mode=\"min\"):\n",
    "    history = {}\n",
    "\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        printlog(\"Epoch {0} / {1}\".format(epoch, epochs))\n",
    "\n",
    "        # 1，训练 -------------------------------------------------\n",
    "        train_step_runner = StepRunner(net=net, stage=\"train\",\n",
    "                                       loss_fn=loss_fn, metrics_dict=deepcopy(metrics_dict),\n",
    "                                       optimizer=optimizer)\n",
    "        train_epoch_runner = EpochRunner(train_step_runner)\n",
    "        train_metrics = train_epoch_runner(train_data)\n",
    "\n",
    "        for name, metric in train_metrics.items():\n",
    "            history[name] = history.get(name, []) + [metric]\n",
    "\n",
    "        # 2，验证 -------------------------------------------------\n",
    "        if val_data:\n",
    "            val_step_runner = StepRunner(net=net, stage=\"val\",\n",
    "                                         loss_fn=loss_fn, metrics_dict=deepcopy(metrics_dict))\n",
    "            val_epoch_runner = EpochRunner(val_step_runner)\n",
    "            with torch.no_grad():\n",
    "                val_metrics = val_epoch_runner(val_data)\n",
    "            val_metrics[\"epoch\"] = epoch\n",
    "            for name, metric in val_metrics.items():\n",
    "                history[name] = history.get(name, []) + [metric]\n",
    "\n",
    "        # 3，早停 -------------------------------------------------\n",
    "        arr_scores = history[monitor]\n",
    "        best_score_idx = np.argmax(arr_scores) if mode == \"max\" else np.argmin(arr_scores)\n",
    "        if best_score_idx == len(arr_scores) - 1:\n",
    "            torch.save(net.state_dict(), ckpt_path)\n",
    "            print(\"<<<<<< reach best {0} : {1} >>>>>>\".format(monitor,\n",
    "                                                              arr_scores[best_score_idx]), file=sys.stderr)\n",
    "        if len(arr_scores) - best_score_idx > patience:\n",
    "            print(\"<<<<<< {} without improvement in {} epoch, early stopping >>>>>>\".format(\n",
    "                monitor, patience), file=sys.stderr)\n",
    "            break\n",
    "        net.load_state_dict(torch.load(ckpt_path))\n",
    "\n",
    "    return pd.DataFrame(history)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76a95080",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchmetrics\n",
    "\n",
    "\n",
    "# 自定义准确度度量指标类，继承自 torchmetrics.Accuracy\n",
    "class Accuracy(torchmetrics.Accuracy):\n",
    "    def __init__(self, dist_sync_on_step=False):\n",
    "        super().__init__(dist_sync_on_step=dist_sync_on_step)\n",
    "\n",
    "    def update(self, preds: torch.Tensor, targets: torch.Tensor):\n",
    "        # 在计算准确度时，使用 sigmoid 函数将预测值转换为概率形式，然后进行计算\n",
    "        super().update(torch.sigmoid(preds), targets.long())\n",
    "\n",
    "    def compute(self):\n",
    "        return super().compute()\n",
    "\n",
    "\n",
    "# 定义损失函数、优化器和度量指标\n",
    "loss_fn = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=0.01)\n",
    "\n",
    "# 创建度量指标字典，包括自定义的准确度度量指标\n",
    "metrics_dict = {\"acc\": Accuracy(task='binary')}\n",
    "\n",
    "# 使用 train_model 函数进行模型训练\n",
    "dfhistory = train_model(net,\n",
    "                        optimizer,\n",
    "                        loss_fn,\n",
    "                        metrics_dict,\n",
    "                        train_data=dl_train,\n",
    "                        val_data=dl_val,\n",
    "                        epochs=10,\n",
    "                        patience=5,\n",
    "                        monitor=\"val_acc\",\n",
    "                        mode=\"max\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94c82203",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2534de95",
   "metadata": {},
   "source": [
    "### 四，评估模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ead5148",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfhistory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d17bb6de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入绘图库\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# 定义绘制度量指标曲线的函数\n",
    "def plot_metric(dfhistory, metric):\n",
    "    # 从训练历史数据帧中提取训练和验证的度量指标值\n",
    "    train_metrics = dfhistory[\"train_\" + metric]\n",
    "    val_metrics = dfhistory['val_' + metric]\n",
    "\n",
    "    # 创建 x 轴的 epoch 数组\n",
    "    epochs = range(1, len(train_metrics) + 1)\n",
    "\n",
    "    # 绘制训练集和验证集度量指标的曲线\n",
    "    plt.plot(epochs, train_metrics, 'bo--')  # 训练集度量指标的蓝色圆点线\n",
    "    plt.plot(epochs, val_metrics, 'ro-')  # 验证集度量指标的红色实线\n",
    "\n",
    "    # 设置图表标题和轴标签\n",
    "    plt.title('Training and validation ' + metric)\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(metric)\n",
    "\n",
    "    # 添加图例，标明曲线含义\n",
    "    plt.legend([\"train_\" + metric, 'val_' + metric])\n",
    "\n",
    "    # 显示图表\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9350e7e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_metric(dfhistory, \"loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d790db14",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_metric(dfhistory, \"acc\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "997c21b1",
   "metadata": {},
   "source": [
    "### 五，使用模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49191373",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义一个函数用于进行预测\n",
    "def predict(net, dl):\n",
    "    # 设置模型为评估模式，以便 dropout 层不生效\n",
    "    net.eval()\n",
    "\n",
    "    # 使用 torch.no_grad() 上下文管理器，关闭梯度计算，加速预测过程\n",
    "    with torch.no_grad():\n",
    "        # 对数据加载器中的每个样本进行预测，并将结果拼接成一个张量\n",
    "        result = nn.Sigmoid()(torch.cat([net.forward(t[0]) for t in dl]))\n",
    "\n",
    "    # 返回预测结果的数据\n",
    "    return result.data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2df2bf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#预测概率\n",
    "y_pred_probs = predict(net, dl_val)\n",
    "y_pred_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60b72dac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#预测类别\n",
    "y_pred = torch.where(y_pred_probs > 0.5,\n",
    "                     torch.ones_like(y_pred_probs), torch.zeros_like(y_pred_probs))\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d6f7881",
   "metadata": {},
   "source": [
    "### 六，保存模型"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63c666ad",
   "metadata": {},
   "source": [
    "推荐使用保存参数方式保存Pytorch模型。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "878b235b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(net.state_dict().keys())  #输出模型状态字典中的键的列表，每个键对应一个模型的参数或层的名称。这些键通常包括卷积层的权重、偏置项、线性层的权重、偏置项等等。查看这些键可以帮助您了解模型的结构和参数情况。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 保存模型参数到文件\n",
    "torch.save(net.state_dict(), \"./data/net_parameter.pt\")\n",
    "\n",
    "# 创建一个新的模型对象并加载保存的参数\n",
    "net_clone = Net()\n",
    "net_clone.load_state_dict(torch.load(\"./data/net_parameter.pt\"))\n",
    "\n",
    "# 使用加载后的模型进行预测\n",
    "y_pred_probs_clone = predict(net_clone, dl_val)\n",
    "\n",
    "# 输出预测结果\n",
    "print(y_pred_probs_clone)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d128841f"
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
