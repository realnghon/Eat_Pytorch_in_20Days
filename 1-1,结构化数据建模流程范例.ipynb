{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c1084315",
   "metadata": {},
   "source": [
    "# 1-1,结构化数据建模流程范例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e707554e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "#mac系统上pytorch和matplotlib在jupyter中同时跑需要更改环境变量\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"] = \"TRUE\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f74d1bbf",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "!pip install torch\n",
    "!pip install -U torchkeras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83c3b159",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchkeras\n",
    "\n",
    "print(\"torch.__version__ = \", torch.__version__)\n",
    "print(\"torchkeras.__version__ = \", torchkeras.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "021a78c0",
   "metadata": {},
   "source": [
    "### 一，准备数据"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22985769",
   "metadata": {},
   "source": [
    "titanic数据集的目标是根据乘客信息预测他们在Titanic号撞击冰山沉没后能否生存。\n",
    "\n",
    "结构化数据一般会使用Pandas中的DataFrame进行预处理。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af13fa86",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "dftrain_raw = pd.read_csv('./eat_pytorch_datasets/titanic/train.csv')\n",
    "dftest_raw = pd.read_csv('./eat_pytorch_datasets/titanic/test.csv')\n",
    "dftrain_raw.head(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7edf254",
   "metadata": {},
   "source": [
    "字段说明：\n",
    "\n",
    "* Survived:0代表死亡，1代表存活【y标签】\n",
    "* Pclass:乘客所持票类，有三种值(1,2,3) 【转换成onehot编码】\n",
    "* Name:乘客姓名 【舍去】\n",
    "* Sex:乘客性别 【转换成bool特征】\n",
    "* Age:乘客年龄(有缺失) 【数值特征，添加“年龄是否缺失”作为辅助特征】\n",
    "* SibSp:乘客兄弟姐妹/配偶的个数(整数值) 【数值特征】\n",
    "* Parch:乘客父母/孩子的个数(整数值)【数值特征】\n",
    "* Ticket:票号(字符串)【舍去】\n",
    "* Fare:乘客所持票的价格(浮点数，0-500不等) 【数值特征】\n",
    "* Cabin:乘客所在船舱(有缺失) 【添加“所在船舱是否缺失”作为辅助特征】\n",
    "* Embarked:乘客登船港口:S、C、Q(有缺失)【转换成onehot编码，四维度 S,C,Q,nan】\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a726f38",
   "metadata": {},
   "source": [
    "利用Pandas的数据可视化功能我们可以简单地进行探索性数据分析EDA（Exploratory Data Analysis）。\n",
    "\n",
    "label分布情况"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78e13165",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'png'\n",
    "# 从DataFrame中获取'Survived'列的值计数，并绘制柱状图\n",
    "# kind='bar'表示绘制柱状图，figsize=(12, 8)设置图形大小，fontsize=15设置字体大小，rot=0表示不旋转X轴标签\n",
    "ax = dftrain_raw['Survived'].value_counts().plot(kind='bar',\n",
    "                                                 figsize=(12, 8), fontsize=15, rot=0)\n",
    "ax.set_ylabel('Counts', fontsize=15)\n",
    "ax.set_xlabel('Survived', fontsize=15)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f6fa85c",
   "metadata": {},
   "source": [
    "年龄分布情况"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2284f17f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'png'\n",
    "\n",
    "# 从数据框（DataFrame）中选择 'Age' 列，并绘制直方图\n",
    "ax = dftrain_raw['Age'].plot(kind='hist',  # 使用直方图绘制\n",
    "                             bins=20,  # 将数据分成20个区间\n",
    "                             color='green',  # 设置直方图的颜色为紫色\n",
    "                             figsize=(12, 8),  # 设置图的尺寸为12x8英寸\n",
    "                             fontsize=10)  # 设置字体大小为15\n",
    "\n",
    "# 设置y轴标签\n",
    "ax.set_ylabel('Frequency', fontsize=15)  # 设置y轴标签为'Frequency'，字体大小为15\n",
    "\n",
    "# 设置x轴标签\n",
    "ax.set_xlabel('Age', fontsize=15)  # 设置x轴标签为'Age'，字体大小为15\n",
    "\n",
    "# 显示绘制的图形\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25ab6193",
   "metadata": {},
   "source": [
    "年龄和label的相关性"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8a0979c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'png'\n",
    "\n",
    "# 从数据框（DataFrame）中筛选 'Survived' 列等于 0 的数据，并绘制年龄（'Age'）的密度图\n",
    "ax = dftrain_raw.query('Survived == 0')['Age'].plot(kind='density',  # 使用密度图绘制\n",
    "                                                    figsize=(12, 8),  # 设置图的尺寸为12x8英寸\n",
    "                                                    fontsize=15)  # 设置字体大小为15\n",
    "\n",
    "# 从数据框中筛选 'Survived' 列等于 1 的数据，并绘制年龄的密度图\n",
    "dftrain_raw.query('Survived == 1')['Age'].plot(kind='density',  # 使用密度图绘制\n",
    "                                               figsize=(12, 8),  # 设置图的尺寸为12x8英寸\n",
    "                                               fontsize=15)  # 设置字体大小为15\n",
    "\n",
    "# 添加图例，用于区分 Survived==0 和 Survived==1 的密度图\n",
    "ax.legend(['Survived==0', 'Survived==1'], fontsize=12)\n",
    "\n",
    "# 设置y轴标签\n",
    "ax.set_ylabel('Density', fontsize=15)  # 设置y轴标签为'Density'，字体大小为15\n",
    "\n",
    "# 设置x轴标签\n",
    "ax.set_xlabel('Age', fontsize=15)  # 设置x轴标签为'Age'，字体大小为15\n",
    "\n",
    "# 显示绘制的图形\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4ba0563",
   "metadata": {},
   "source": [
    "**下面为正式的数据预处理**\n",
    "\n",
    "1. `dfPclass = pd.get_dummies(dfdata['Pclass'])`：\n",
    "   - `pd.get_dummies` 是 Pandas 库中的一个函数，用于进行独热编码。它将具有多个不同取值的分类变量（如 'Pclass' 列）转换为多个二进制（0或1）的列，以便更好地用于机器学习模型。\n",
    "   - `dfdata['Pclass']` 表示从名为 `dfdata` 的数据框中选择 'Pclass' 列，并将其传递给 `pd.get_dummies` 函数。\n",
    "   - 结果是一个包含独热编码后数据的新数据框 `dfPclass`。\n",
    "\n",
    "2. `dfPclass.columns = ['Pclass_' + str(x) for x in dfPclass.columns]`：\n",
    "   - 这一行代码用于更改 `dfPclass` 数据框的列名。\n",
    "   - `dfPclass.columns` 返回 `dfPclass` 数据框的列标签。\n",
    "   - `['Pclass_' + str(x) for x in dfPclass.columns]` 是一个列表推导式，用于将每个列标签都修改为以 'Pclass_' 作为前缀，以便更好地标识这些列。\n",
    "\n",
    "3. `dfresult = pd.concat([dfresult, dfPclass], axis=1)`：\n",
    "   - 这一行代码使用 `pd.concat` 函数将 `dfPclass` 数据框与之前的结果数据框 `dfresult` 水平连接（按列连接）。\n",
    "   - `axis=1` 参数表示按列连接，因此将 `dfPclass` 的列添加到 `dfresult` 中。\n",
    "   - 这样，`dfresult` 数据框就包含了 'Pclass' 列的独热编码结果，其中每个不同的 'Pclass' 取值都成为了新的列，列名以 'Pclass_' 为前缀。\n",
    "\n",
    "\n",
    "1. `dfresult['Age'] = dfdata['Age'].fillna(0)`：\n",
    "   - `dfdata['Age']` 表示从数据框 `dfdata` 中选择 'Age' 列的数据。\n",
    "   - `dfdata['Age'].fillna(0)` 用于将 'Age' 列中的缺失值（NaN，Not a Number）替换为 0。这意味着如果某一行的 'Age' 列数据缺失（为 NaN），则在 `dfresult` 数据框中相应的位置会填充为 0。这是一种处理缺失值的方法，将缺失值替换为一个特定的数值。\n",
    "\n",
    "2. `dfresult['Age_null'] = pd.isna(dfdata['Age']).astype('int32')`：\n",
    "   - `pd.isna(dfdata['Age'])` 用于检查 'Age' 列中哪些值是缺失值。返回的结果是一个布尔型的 Series，其中缺失值对应的位置为 True，非缺失值对应的位置为 False。\n",
    "   - `.astype('int32')` 用于将布尔型的 Series 转换为整数型的 Series，将 True 转换为 1，将 False 转换为 0。\n",
    "   - 最终将转换后的整数型 Series 存储在 `dfresult` 数据框中的 'Age_null' 列中。这一列的值表示对应行的 'Age' 是否为缺失值，是缺失值则为 1，否则为 0。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a28dcead",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义数据预处理函数\n",
    "def preprocessing(dfdata):\n",
    "    dfresult = pd.DataFrame()  # 创建一个空的数据框来存储处理后的数据\n",
    "\n",
    "    # 处理 'Pclass' 列，将其转换成独热编码\n",
    "    dfPclass = pd.get_dummies(dfdata['Pclass'])\n",
    "    dfPclass.columns = ['Pclass_' + str(x) for x in dfPclass.columns]  # 为每个编码列添加前缀 'Pclass_'\n",
    "    dfresult = pd.concat([dfresult, dfPclass], axis=1)  # 将编码后的列与结果数据框合并\n",
    "\n",
    "    # 处理 'Sex' 列，将其转换成独热编码\n",
    "    dfSex = pd.get_dummies(dfdata['Sex'])\n",
    "    dfresult = pd.concat([dfresult, dfSex], axis=1)  # 将编码后的列与结果数据框合并\n",
    "\n",
    "    # 处理 'Age' 列，将缺失值用 0 填充，并添加一个新列 'Age_null' 以表示是否有缺失值\n",
    "    dfresult['Age'] = dfdata['Age'].fillna(0)\n",
    "    dfresult['Age_null'] = pd.isna(dfdata['Age']).astype('int32')  # 将缺失值转换为 0 和 1\n",
    "\n",
    "    # 处理 'SibSp', 'Parch', 'Fare' 列，直接将它们加入结果数据框\n",
    "    dfresult['SibSp'] = dfdata['SibSp']\n",
    "    dfresult['Parch'] = dfdata['Parch']\n",
    "    dfresult['Fare'] = dfdata['Fare']\n",
    "\n",
    "    # 处理 'Cabin' 列，添加一个新列 'Cabin_null' 表示是否有缺失值\n",
    "    dfresult['Cabin_null'] = pd.isna(dfdata['Cabin']).astype('int32')\n",
    "\n",
    "    # 处理 'Embarked' 列，将其转换成独热编码\n",
    "    dfEmbarked = pd.get_dummies(dfdata['Embarked'], dummy_na=True)  # 使用dummy_na=True来处理缺失值\n",
    "    dfEmbarked.columns = ['Embarked_' + str(x) for x in dfEmbarked.columns]  # 为每个编码列添加前缀 'Embarked_'\n",
    "    dfresult = pd.concat([dfresult, dfEmbarked], axis=1)  # 将编码后的列与结果数据框合并\n",
    "\n",
    "    return dfresult  # 返回处理后的数据框\n",
    "\n",
    "\n",
    "# 调用数据预处理函数，将训练集和测试集进行预处理\n",
    "x_train = preprocessing(dftrain_raw).values  # 将处理后的数据转换为NumPy数组\n",
    "y_train = dftrain_raw[['Survived']].values  # 获取训练集的标签\n",
    "\n",
    "x_test = preprocessing(dftest_raw).values  # 将处理后的数据转换为NumPy数组\n",
    "y_test = dftest_raw[['Survived']].values  # 获取测试集的标签\n",
    "\n",
    "# 输出数据集的形状信息\n",
    "print(\"x_train.shape =\", x_train.shape)  # 输出训练集特征矩阵的形状\n",
    "print(\"x_test.shape =\", x_test.shape)  # 输出测试集特征矩阵的形状\n",
    "print(\"y_train.shape =\", y_train.shape)  # 输出训练集标签的形状\n",
    "print(\"y_test.shape =\", y_test.shape)  # 输出测试集标签的形状\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95d6c6d9",
   "metadata": {},
   "source": [
    "进一步使用DataLoader和TensorDataset封装成可以迭代的数据管道。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d744935",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建训练数据加载器 dl_train\n",
    "dl_train = DataLoader(\n",
    "    TensorDataset(torch.tensor(x_train).float(), torch.tensor(y_train).float()),  # 使用TensorDataset包装训练数据\n",
    "    shuffle=True,  # 随机洗牌训练数据，以增加训练的随机性\n",
    "    batch_size=8  # 设置每个小批量的大小为8\n",
    ")\n",
    "\n",
    "# 创建验证数据加载器 dl_val\n",
    "dl_val = DataLoader(\n",
    "    TensorDataset(torch.tensor(x_test).float(), torch.tensor(y_test).float()),  # 使用TensorDataset包装验证数据\n",
    "    shuffle=False,  # 不洗牌验证数据，以确保验证结果的可重复性\n",
    "    batch_size=8  # 设置每个小批量的大小为8，与训练时一致\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ec2fc6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 迭代训练数据加载器 dl_train 中的数据批次\n",
    "for features, labels in dl_train:\n",
    "    print(\"Features:\", features)  # 打印当前数据批次的特征\n",
    "    print(\"Labels:\", labels)  # 打印当前数据批次的标签\n",
    "    break  # 使用 break 语句来退出循环，只打印第一个数据批次\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25126768",
   "metadata": {},
   "source": [
    "### 二，定义模型"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a275e98",
   "metadata": {},
   "source": [
    "使用Pytorch通常有三种方式构建模型：使用nn.Sequential按层顺序构建模型，继承nn.Module基类构建自定义模型，继承nn.Module基类构建模型并辅助应用模型容器进行封装。\n",
    "\n",
    "此处选择使用最简单的nn.Sequential，按层顺序模型。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "617186ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义创建神经网络的函数\n",
    "def create_net():\n",
    "    net = nn.Sequential()  # 创建一个Sequential容器，用于按顺序堆叠神经网络的层次\n",
    "\n",
    "    # 添加第一个全连接层，输入特征数为15，输出特征数为20\n",
    "    net.add_module(\"linear1\", nn.Linear(15, 20))\n",
    "    net.add_module(\"relu1\", nn.ReLU())  # 添加ReLU激活函数\n",
    "\n",
    "    # 添加第二个全连接层，输入特征数为20，输出特征数为15\n",
    "    net.add_module(\"linear2\", nn.Linear(20, 15))\n",
    "    net.add_module(\"relu2\", nn.ReLU())  # 添加ReLU激活函数\n",
    "\n",
    "    # 添加第三个全连接层，输入特征数为15，输出特征数为1，用于二元分类\n",
    "    net.add_module(\"linear3\", nn.Linear(15, 1))\n",
    "\n",
    "    return net\n",
    "\n",
    "\n",
    "# 调用创建神经网络的函数，创建一个名为net的神经网络模型\n",
    "net = create_net()\n",
    "\n",
    "# 打印神经网络的结构\n",
    "print(net)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6761227a",
   "metadata": {},
   "source": [
    "### 三，训练模型"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af89d5af",
   "metadata": {},
   "source": [
    "Pytorch通常需要用户编写自定义训练循环，训练循环的代码风格因人而异。\n",
    "\n",
    "有3类典型的训练循环代码风格：脚本形式训练循环，函数形式训练循环，类形式训练循环。\n",
    "\n",
    "此处介绍一种较通用的仿照Keras风格的脚本形式的训练循环。\n",
    "\n",
    "该脚本形式的训练代码与 torchkeras 库的核心代码基本一致。\n",
    "\n",
    "torchkeras详情:  https://github.com/lyhue1991/torchkeras \n",
    "\n",
    "以下是代码中计算指标部分的详细说明：\n",
    "\n",
    "在这部分代码中，首先将神经网络模型切换到训练模式，然后迭代训练数据加载器 (`dl_train`) 中的数据批次。以下是详细说明：\n",
    "\n",
    "- `net.train()`: 设置神经网络模型为训练模式，这一步是为了激活训练中使用的一些特定功能，例如Dropout层和Batch Normalization层中的训练模式。\n",
    "\n",
    "- `total_loss` 和 `step`: 用于累积每个数据批次的损失值和迭代次数。\n",
    "\n",
    "- `loop`: 使用 tqdm 库创建一个迭代器，用于显示训练进度，并通过 `enumerate` 函数遍历训练数据加载器中的数据批次。`total` 参数用于设置迭代的总次数。\n",
    "\n",
    "- `train_metrics_dict`: 用深拷贝 (`deepcopy`) 创建一个字典，其中包含了用于存储本轮训练过程中评估指标的对象。\n",
    "\n",
    "- 在每个数据批次的迭代中，进行以下操作：\n",
    "    - `features` 和 `labels`: 从当前数据批次中获取特征和标签。\n",
    "\n",
    "    - 前向传播 (`preds = net(features)`)：将特征输入神经网络，获得预测值 `preds`。\n",
    "\n",
    "    - 计算损失值 (`loss = loss_fn(preds, labels)`)：使用预测值和真实标签计算损失值，这里使用的损失函数是二元交叉熵损失函数。\n",
    "\n",
    "    - 反向传播 (`loss.backward()`)：根据损失值计算梯度并反向传播，以便更新神经网络的参数。\n",
    "\n",
    "    - 优化器步骤 (`optimizer.step()`)：根据计算的梯度更新模型参数。\n",
    "\n",
    "    - 优化器梯度清零 (`optimizer.zero_grad()`)：清零优化器中的梯度，准备处理下一个数据批次。\n",
    "\n",
    "    - 计算并记录训练指标 (`step_metrics`)：使用评估指标对象计算并记录每个数据批次的训练指标，例如准确度。\n",
    "\n",
    "    - 记录当前数据批次的损失值和指标，并更新 `total_loss` 和 `step`。\n",
    "\n",
    "    - 使用 `tqdm` 更新进度条信息，显示当前数据批次的损失值和指标。\n",
    "\n",
    "- 在每个 epoch 结束时，计算并记录整个 epoch 的平均损失值和指标，并将其添加到 `history` 字典中。\n",
    "\n",
    "- 最后，重置评估指标对象的状态，以准备处理下一个 epoch。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87c5039d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入必要的库\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from copy import deepcopy\n",
    "from torchkeras.metrics import Accuracy  # 导入自定义指标Accuracy\n",
    "\n",
    "\n",
    "# 定义一个打印日志信息的函数\n",
    "def printlog(info):\n",
    "    nowtime = datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "    print(\"\\n\" + \"==========\" * 8 + \"%s\" % nowtime)\n",
    "    print(str(info) + \"\\n\")\n",
    "\n",
    "\n",
    "# 使用二元交叉熵损失函数创建损失函数对象\n",
    "loss_fn = nn.BCEWithLogitsLoss()\n",
    "\n",
    "# 使用Adam优化器进行模型参数的优化，学习率为0.01\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=0.01)\n",
    "\n",
    "# 定义一个字典，用于存储模型评估指标，这里包括准确度\n",
    "metrics_dict = {\"acc\": Accuracy()}\n",
    "\n",
    "# 训练的总轮数\n",
    "epochs = 20\n",
    "\n",
    "# 定义用于保存最佳模型权重的文件路径\n",
    "ckpt_path = 'checkpoint.pt'\n",
    "\n",
    "# Early Stopping 相关设置\n",
    "monitor = \"val_acc\"  # 用于监控模型性能的指标\n",
    "patience = 5  # 当连续多少轮性能没有提升时，触发早停\n",
    "mode = \"max\"  # 监控指标的模式，\"max\"表示监控指标越大越好\n",
    "\n",
    "# 存储训练历史信息的字典\n",
    "history = {}\n",
    "\n",
    "# 开始训练循环\n",
    "for epoch in range(1, epochs + 1):\n",
    "    printlog(\"Epoch {0} / {1}\".format(epoch, epochs))\n",
    "\n",
    "    # 1，训练阶段 -------------------------------------------------\n",
    "    net.train()  # 设置模型为训练模式\n",
    "\n",
    "    total_loss, step = 0, 0\n",
    "\n",
    "    # 使用tqdm库显示训练进度，并设置文件输出为sys.stdout\n",
    "    loop = tqdm(enumerate(dl_train), total=len(dl_train), file=sys.stdout)\n",
    "    train_metrics_dict = deepcopy(metrics_dict)  # 复制评估指标字典，用于存储本轮训练的指标值\n",
    "\n",
    "    for i, batch in loop:\n",
    "\n",
    "        features, labels = batch\n",
    "        # 前向传播\n",
    "        preds = net(features)\n",
    "        loss = loss_fn(preds, labels)\n",
    "\n",
    "        # 反向传播\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # 计算指标\n",
    "        step_metrics = {\"train_\" + name: metric_fn(preds, labels).item()\n",
    "                        for name, metric_fn in train_metrics_dict.items()}\n",
    "\n",
    "        # 创建包含本步骤的训练损失和指标的字典\n",
    "        step_log = dict({\"train_loss\": loss.item()}, **step_metrics)\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        step += 1\n",
    "        if i != len(dl_train) - 1:\n",
    "            loop.set_postfix(**step_log)\n",
    "        else:\n",
    "            # 如果是本轮的最后一个批次，计算本轮的平均训练损失\n",
    "            epoch_loss = total_loss / step\n",
    "\n",
    "            # 计算并记录本轮的平均训练指标\n",
    "            epoch_metrics = {\"train_\" + name: metric_fn.compute().item()\n",
    "                             for name, metric_fn in train_metrics_dict.items()}\n",
    "\n",
    "            # 创建包含本轮的平均训练损失和指标的字典\n",
    "            epoch_log = dict({\"train_loss\": epoch_loss}, **epoch_metrics)\n",
    "\n",
    "            # 更新进度条的显示，显示本轮的平均训练损失和指标\n",
    "            loop.set_postfix(**epoch_log)\n",
    "\n",
    "            # 重置本轮的训练指标，以便下一轮使用\n",
    "            for name, metric_fn in train_metrics_dict.items():\n",
    "                metric_fn.reset()\n",
    "\n",
    "    # 将本轮的训练损失和指标记录到训练历史中\n",
    "    for name, metric in epoch_log.items():\n",
    "        history[name] = history.get(name, []) + [metric]\n",
    "\n",
    "    # 2，验证阶段 -------------------------------------------------\n",
    "    net.eval()  # 设置模型为评估模式\n",
    "\n",
    "    total_loss, step = 0, 0\n",
    "    loop = tqdm(enumerate(dl_val), total=len(dl_val), file=sys.stdout)\n",
    "\n",
    "    val_metrics_dict = deepcopy(metrics_dict)  # 复制评估指标字典，用于存储本轮验证的指标值\n",
    "\n",
    "    with torch.no_grad():  # 不计算梯度\n",
    "        for i, batch in loop:\n",
    "\n",
    "            features, labels = batch\n",
    "\n",
    "            # 前向传播\n",
    "            preds = net(features)\n",
    "            loss = loss_fn(preds, labels)\n",
    "\n",
    "            # 计算指标\n",
    "            step_metrics = {\"val_\" + name: metric_fn(preds, labels).item()\n",
    "                            for name, metric_fn in val_metrics_dict.items()}\n",
    "\n",
    "            # 创建包含本步骤的验证损失和指标的字典\n",
    "            step_log = dict({\"val_loss\": loss.item()}, **step_metrics)\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            step += 1\n",
    "            if i != len(dl_val) - 1:\n",
    "                loop.set_postfix(**step_log)\n",
    "            else:\n",
    "                # 如果是本轮的最后一个批次，计算本轮的平均验证损失\n",
    "                epoch_loss = (total_loss / step)\n",
    "\n",
    "                # 计算并记录本轮的平均验证指标\n",
    "                epoch_metrics = {\"val_\" + name: metric_fn.compute().item()\n",
    "                                 for name, metric_fn in val_metrics_dict.items()}\n",
    "\n",
    "                # 创建包含本轮的平均验证损失和指标的字典\n",
    "                epoch_log = dict({\"val_loss\": epoch_loss}, **epoch_metrics)\n",
    "\n",
    "                # 更新进度条的显示，显示本轮的平均验证损失和指标\n",
    "                loop.set_postfix(**epoch_log)\n",
    "\n",
    "                # 重置本轮的验证指标，以便下一轮使用\n",
    "                for name, metric_fn in val_metrics_dict.items():\n",
    "                    metric_fn.reset()\n",
    "\n",
    "    # 将本轮的验证损失和指标记录到训练历史中\n",
    "    epoch_log[\"epoch\"] = epoch\n",
    "    for name, metric in epoch_log.items():\n",
    "        history[name] = history.get(name, []) + [metric]\n",
    "\n",
    "    # 3，Early Stopping -------------------------------------------------\n",
    "    arr_scores = history[monitor]  # 获取历史上的监控指标数值\n",
    "    best_score_idx = np.argmax(arr_scores) if mode == \"max\" else np.argmin(arr_scores)\n",
    "\n",
    "    # 如果当前的模型性能比历史上的最佳性能好，保存当前模型权重\n",
    "    if best_score_idx == len(arr_scores) - 1:\n",
    "        torch.save(net.state_dict(), ckpt_path)\n",
    "        print(\"<<<<<< reach best {0} : {1} >>>>>>\".format(monitor,\n",
    "                                                          arr_scores[best_score_idx]), file=sys.stderr)\n",
    "\n",
    "    # 如果连续多轮性能没有提升，触发早停\n",
    "    if len(arr_scores) - best_score_idx > patience:\n",
    "        print(\"<<<<<< {} without improvement in {} epoch, early stopping >>>>>>\".format(\n",
    "            monitor, patience), file=sys.stderr)\n",
    "        break\n",
    "\n",
    "    # 恢复历史上的最佳模型权重\n",
    "    net.load_state_dict(torch.load(ckpt_path))\n",
    "\n",
    "# 将训练历史信息转为DataFrame格式\n",
    "dfhistory = pd.DataFrame(history)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70f7f3b3",
   "metadata": {},
   "source": [
    "### 四，评估模型"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cefbce96",
   "metadata": {},
   "source": [
    "我们首先评估一下模型在训练集和验证集上的效果。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a731173",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfhistory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10ab56d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'svg'  # 指定绘图格式为SVG\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# 定义一个函数，用于绘制训练和验证指标曲线\n",
    "def plot_metric(dfhistory, metric):\n",
    "    # 从训练历史数据中获取训练和验证指标的数值\n",
    "    train_metrics = dfhistory[\"train_\" + metric]\n",
    "    val_metrics = dfhistory['val_' + metric]\n",
    "    # 创建一个表示轮次的范围\n",
    "    epochs = range(1, len(train_metrics) + 1)\n",
    "    # 绘制训练指标曲线，使用蓝色圆点形状的线条\n",
    "    plt.plot(epochs, train_metrics, 'bo--')\n",
    "    # 绘制验证指标曲线，使用红色实线的线条\n",
    "    plt.plot(epochs, val_metrics, 'ro-')\n",
    "    # 设置图表标题\n",
    "    plt.title('Training and validation ' + metric)\n",
    "    # 设置X轴标签\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    # 设置Y轴标签\n",
    "    plt.ylabel(metric)\n",
    "    # 添加图例，表示训练和验证指标对应的线条\n",
    "    plt.legend([\"train_\" + metric, 'val_' + metric])\n",
    "    # 显示图表\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3b47c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_metric(dfhistory, \"loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bdfcf5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_metric(dfhistory, \"acc\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05c4494b",
   "metadata": {},
   "source": [
    "### 五，使用模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da16f9ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用神经网络进行推断，计算前10个样本的预测概率\n",
    "# 使用 torch.sigmoid 函数将模型输出的 logits 转换为概率值\n",
    "\n",
    "y_pred_probs = torch.sigmoid(\n",
    "    net(torch.tensor(x_test[0:10]).float())  # 将前10个测试样本转换为 PyTorch 张量并进行推断\n",
    ").data\n",
    "\n",
    "# 输出预测概率值\n",
    "y_pred_probs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a31cb281",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 预测类别\n",
    "# 如果预测的概率值大于0.5，则将类别设置为1，否则设置为0\n",
    "\n",
    "# 使用 torch.where 函数进行类别的判定\n",
    "y_pred = torch.where(\n",
    "    y_pred_probs > 0.5,  # 预测概率值大于0.5时，为正类别\n",
    "    torch.ones_like(y_pred_probs),  # 正类别标签（1）\n",
    "    torch.zeros_like(y_pred_probs)  # 负类别标签（0）\n",
    ")\n",
    "\n",
    "# 输出预测的类别\n",
    "y_pred\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57fe8bba",
   "metadata": {},
   "source": [
    "### 六，保存模型"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89eb7506",
   "metadata": {},
   "source": [
    "Pytorch 有两种保存模型的方式，都是通过调用pickle序列化方法实现的。\n",
    "\n",
    "第一种方法只保存模型参数。\n",
    "\n",
    "第二种方法保存完整模型。\n",
    "\n",
    "推荐使用第一种，第二种方法可能在切换设备和目录的时候出现各种问题。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9113eb43",
   "metadata": {},
   "source": [
    "**1，保存模型参数(推荐)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6098000",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 打印神经网络模型的状态字典中的所有键\n",
    "print(net.state_dict().keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cfa68ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存模型参数到文件 \"./data/net_parameter.pt\"\n",
    "torch.save(net.state_dict(), \"./data/net_parameter.pt\")\n",
    "\n",
    "# 创建一个新的神经网络模型 net_clone\n",
    "net_clone = create_net()\n",
    "\n",
    "# 加载保存的模型参数到 net_clone\n",
    "net_clone.load_state_dict(torch.load(\"./data/net_parameter.pt\"))\n",
    "\n",
    "# 对前10个测试样本进行推断，使用新的模型 net_clone\n",
    "# 使用 torch.sigmoid 函数将模型输出的 logits 转换为概率值\n",
    "predictions = torch.sigmoid(net_clone.forward(torch.tensor(x_test[0:10]).float())).data\n",
    "\n",
    "# 输出预测的概率值\n",
    "predictions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bee51ce5",
   "metadata": {},
   "source": [
    "**2，保存完整模型(不推荐)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c969c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存整个神经网络模型到文件 \"./data/net_model.pt\"\n",
    "torch.save(net, './data/net_model.pt')\n",
    "\n",
    "# 加载整个神经网络模型\n",
    "net_loaded = torch.load('./data/net_model.pt')\n",
    "\n",
    "# 对前10个测试样本进行推断，使用加载的模型 net_loaded\n",
    "# 使用 torch.sigmoid 函数将模型输出的 logits 转换为概率值\n",
    "predictions = torch.sigmoid(net_loaded(torch.tensor(x_test[0:10]).float())).data\n",
    "\n",
    "# 输出预测的概率值\n",
    "predictions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52eacb75",
   "metadata": {},
   "source": [
    "**如果本书对你有所帮助，想鼓励一下作者，记得给本项目加一颗星星star⭐️，并分享给你的朋友们喔😊!** \n",
    "\n",
    "如果对本书内容理解上有需要进一步和作者交流的地方，欢迎在公众号\"算法美食屋\"下留言。作者时间和精力有限，会酌情予以回复。\n",
    "\n",
    "也可以在公众号后台回复关键字：**加群**，加入读者交流群和大家讨论。\n",
    "\n",
    "![算法美食屋logo.png](https://tva1.sinaimg.cn/large/e6c9d24egy1h41m2zugguj20k00b9q46.jpg)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "formats": "ipynb,md"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
